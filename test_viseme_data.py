#!/usr/bin/env python3
"""
Simple test script to show viseme data structure for developers
This script demonstrates the exact format of viseme data generated by ElevenLabs
"""

import asyncio
import json
import time
from elevenlabs_service import ElevenLabsService
from config import ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID

async def test_viseme_generation():
    """Test viseme data generation and show the structure"""
    print("üé≠ Viseme Data Structure Test")
    print("=" * 50)
    
    # Initialize ElevenLabs service
    elevenlabs_service = ElevenLabsService()
    
    # Test text samples
    test_texts = [
        "Hello, how are you today?",
        "Welcome to Kan-Guroo educational programs!",
        "We offer exchange programs in the USA and Europe.",
        "Our team includes Otari, Saba, and Lasha as founders."
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nüìù Test {i}: '{text}'")
        print("-" * 30)
        
        try:
            # Generate audio and viseme data
            audio_path = f"viseme_test_{i}_{int(time.time())}.mp3"
            audio_file, viseme_data = await elevenlabs_service.text_to_speech_with_visemes(text, audio_path)
            
            if viseme_data:
                print(f"‚úÖ Viseme data generated successfully")
                print(f"üìä Structure:")
                print(f"  ‚Ä¢ Total visemes: {len(viseme_data.get('visemes', []))}")
                print(f"  ‚Ä¢ Duration: {viseme_data.get('duration', 0):.2f} seconds")
                print(f"  ‚Ä¢ Original text: '{viseme_data.get('text', 'N/A')}'")
                
                # Show the exact JSON structure
                print(f"\nüîß Raw Viseme Data (JSON):")
                print(json.dumps(viseme_data, indent=2))
                
                # Show viseme breakdown
                print(f"\nüìã Viseme Breakdown:")
                visemes = viseme_data.get('visemes', [])
                for j, viseme in enumerate(visemes):
                    print(f"  {j+1:2d}. Time: {viseme.get('time', 0):.2f}s ‚Üí Viseme: {viseme.get('viseme', 'N/A')}")
                
                # Show viseme frequency
                viseme_counts = {}
                for viseme in visemes:
                    v_name = viseme.get('viseme', 'unknown')
                    viseme_counts[v_name] = viseme_counts.get(v_name, 0) + 1
                
                print(f"\nüìà Viseme Frequency:")
                for viseme_name, count in sorted(viseme_counts.items()):
                    percentage = (count / len(visemes)) * 100
                    print(f"  {viseme_name}: {count} times ({percentage:.1f}%)")
                
            else:
                print(f"‚ùå No viseme data generated")
                
        except Exception as e:
            print(f"‚ùå Error: {e}")
        
        print("\n" + "=" * 50)

def show_viseme_reference():
    """Show viseme reference for developers"""
    print("\nüé≠ Viseme Reference Guide")
    print("=" * 50)
    
    viseme_reference = {
        'viseme_sil': {
            'description': 'Silence - closed mouth',
            'intensity': 0.0,
            'use_case': 'Pauses, silence between words'
        },
        'viseme_aa': {
            'description': 'A sound - open mouth',
            'intensity': 0.8,
            'use_case': 'Words like "cat", "hat", "bat"'
        },
        'viseme_ee': {
            'description': 'E sound - smile shape',
            'intensity': 0.8,
            'use_case': 'Words like "see", "tree", "free"'
        },
        'viseme_ii': {
            'description': 'I sound - narrow smile',
            'intensity': 0.7,
            'use_case': 'Words like "bit", "sit", "fit"'
        },
        'viseme_oo': {
            'description': 'O sound - rounded lips',
            'intensity': 1.0,
            'use_case': 'Words like "boat", "coat", "note"'
        },
        'viseme_uu': {
            'description': 'U sound - puckered lips',
            'intensity': 0.8,
            'use_case': 'Words like "boot", "suit", "fruit"'
        },
        'viseme_kk': {
            'description': 'K sound - closed mouth',
            'intensity': 0.2,
            'use_case': 'Words like "cat", "key", "back"'
        },
        'viseme_PP': {
            'description': 'P sound - lips together',
            'intensity': 0.8,
            'use_case': 'Words like "pat", "pet", "put"'
        },
        'viseme_ff': {
            'description': 'F sound - lip touch',
            'intensity': 0.7,
            'use_case': 'Words like "fish", "off", "tough"'
        },
        'viseme_DD': {
            'description': 'D sound - tongue touch',
            'intensity': 0.6,
            'use_case': 'Words like "dog", "bed", "red"'
        },
        'viseme_ss': {
            'description': 'S sound - narrow opening',
            'intensity': 0.6,
            'use_case': 'Words like "snake", "pass", "miss"'
        }
    }
    
    print("üìö Complete Viseme Reference:")
    for viseme, info in viseme_reference.items():
        print(f"\n  {viseme}:")
        print(f"    Description: {info['description']}")
        print(f"    Intensity: {info['intensity']}")
        print(f"    Use Case: {info['use_case']}")

def show_implementation_example():
    """Show how to use viseme data in frontend"""
    print("\nüíª Frontend Implementation Example")
    print("=" * 50)
    
    example_code = '''
// Example: How to use viseme data in JavaScript
function startLipSync(visemeData) {
    const visemes = visemeData.visemes;
    const startTime = Date.now();
    
    function animateViseme() {
        const currentTime = (Date.now() - startTime) / 1000;
        
        // Find current viseme based on time
        let currentViseme = null;
        for (const viseme of visemes) {
            if (viseme.time <= currentTime) {
                currentViseme = viseme;
            } else {
                break;
            }
        }
        
        // Apply viseme to 3D character
        if (currentViseme) {
            applyVisemeToCharacter(currentViseme.viseme);
        }
        
        // Continue animation if not finished
        if (currentTime < visemeData.duration) {
            requestAnimationFrame(animateViseme);
        }
    }
    
    animateViseme();
}

function applyVisemeToCharacter(visemeName) {
    // Map viseme to mouth shape intensity
    const visemeIntensity = getVisemeIntensity(visemeName);
    
    // Apply to character (example methods)
    // Method 1: Blend shapes
    character.morphTargetInfluences[mouthBlendIndex] = visemeIntensity;
    
    // Method 2: Bone animation
    character.jawBone.rotation.x = -visemeIntensity * 0.1;
    
    // Method 3: Scaling
    character.mouthArea.scale.y = 1 + visemeIntensity * 0.1;
}
'''
    
    print("üîß JavaScript Implementation:")
    print(example_code)

async def main():
    """Main function"""
    import time
    
    print("üé≠ Viseme Data Structure Test")
    print("=" * 50)
    print("This script shows developers exactly how viseme data is structured")
    print("and how it can be used for 3D character lip-sync animation")
    print("=" * 50)
    
    # Check API configuration
    if not ELEVENLABS_API_KEY or ELEVENLABS_API_KEY == 'your_elevenlabs_api_key_here':
        print("‚ùå ElevenLabs API key not configured")
        print("   Please set ELEVENLABS_API_KEY in your .env file")
        return
    
    # Show reference information
    show_viseme_reference()
    show_implementation_example()
    
    # Test viseme generation
    await test_viseme_generation()
    
    print("\nüéØ Test Complete!")
    print("=" * 50)
    print("üìÅ Check generated audio files in the project directory")
    print("üîß Use the JSON structure above to implement lip-sync in your frontend")
    print("üí° The viseme data is what drives the 3D character's mouth animation")

if __name__ == "__main__":
    asyncio.run(main())
